.. Python-based use of parametric regression

Parametric regression tutorial
==============================

Introduction
------------

Given a set of observations :math:`(x_i, y_i)`, with :math:`\newcommand{\R}{\mathbb{R}}x_i = (x_{i1},
\ldots, x_{ip})^T \in \R^p`. We assume, there exists a function
:math:`f(\theta, x)` and a set of parameters :math:`\theta \in \R^q`
such that:

.. math::

  \DeclareMathOperator{\argmin}{argmin}
  y_i = f(\theta, x_i) + \epsilon_i

with :math:`\epsilon_i \in \R` such that :math:`E(\epsilon) = 0`.

The objective is to fine the set of parameters `\theta`. Obviously, the real
function is inaccesible. Instead, we will try to find an estimate of the
parameters, :math:`\hat{\theta}` using the least square estimator, which is:

.. math::

  \hat{\theta} = \argmin_{\theta \in \R^q} \left( f(\theta,x_i) - y_i \right)^2

The method is based on the SciPy function ``scipy.optimize.leastsq``, which
relies on the MINPACK's functions ``lmdif`` and ``lmder``. Both functions
implement a modified Levenberg-Marquardt algorithm to solve the least-square
problem. Most of the output of the main curve fitting option will be the output
of the least-square function in scipy.

A simple example
----------------

As a simple example, we will take the function :math:`f` to be:

.. math::

  f((a_0,a_1,a_2),x) = a_0 + a_1 x + a_2 x^2

Let's assume the points look like this:

.. image:: Parm_tut_data.png

The data points have been generated by that script::

  >>> import numpy as np
  >>> from matplotlib import pylab
  >>> x = np.arange(0,3,0.01)
  >>> y = 2*x + 4*x**2 + np.random.randn(*x.shape)
  >>> pylab.plot(x,y,'+',label='data')
  >>> pylab.legend(loc=0)
  >>> pylab.xlabel('X'); pylab.ylabel('Y')

So we will expect to find something close to :math:`(0,2,4)`.

To perform the analysis, we first need to define the function to be fitted::

  >>> def f((a0,a1,a2), x):
  >>>   return a0 + a1*x+ a2*x**2

Then, we construct a :py:class:`CurveFitting` object, which computes and stores the
optimal parameters, and also behaves as a function for the fitted data::

  >>> import pyqt_fit
  >>> fit = pyqt_fit.CurveFitting(x,y,(0,1,0),f)
  >>> print "The parameters are: a0 = {0}, a1 = {1}, a2 = {2}".format(*fit.popt)
  The parameters are: a0 = -0.181581108848, a1 = 2.21486197906, a2 = 3.97872283269
  >>> yfitted = fit(x)

The ``fit`` object, beside being a callable object to evaluate the fitting
function as some points, contain the following properties:

  ``fct``
    Function being fitted (e.g. the one given as argument)

  ``popt``
    Optimal parameters for the function

  ``res``
    Residuals of the fitted data

  ``pcov``
    Covariance of the parameters around the optimal values.

  ``infodict``
    Additional estimation outputs, as given by :py:func:`scipy.optimize.leastsq`

Fitting analysis
^^^^^^^^^^^^^^^^

PyQt-Fit also has tools to evaluate your fitting. You can use them as a whole::

  >>> result= pyqt_fit.fit_evaluation(fit, x, y,
  ...                                 fct_desc = "$y = a_0 + a_1 x + a_2 x^2$",
  ...                                 param_names=['a_0', 'a_1', 'a_2'])

You can then examine the ``result`` variable. But you can also perform only the
analysis you need. For example, you can compute the data needed for the
residual analysis with::

  >>> rm = pyqt_fit.plot_fit.residual_measures(fit.res, fit(x))

``rm`` is a named tuple with the following fields:

  ``scaled_res``
    Scaled residuals, sorted in ascending values for residuals. The scaled
    residuals are computed as :math:`sr_i = \frac{r_i}{\sigma_r}`, where
    :math:`\sigma_r` is the variance of the residuals.

  ``res_IX``
    Ordering indices for the residuals in scaled_res. This orders the residuals
    in an ascending manner.

  ``prob``
    List of quantiles used to compute the normalized quantiles.

  ``normq``
    Value expected for the quantiles in ``prob`` if the distribution is normal.
    The foluma is: :math:`\DeclareMathOperator{\erf}{erf} \Phi(p) = \sqrt{2}
    \erf^{-1}(2p-1), p\in[0;1]`

Plotting the results
^^^^^^^^^^^^^^^^^^^^

At last, you can use the display used for the GUI::

  >>> handles = pyqt_fit.plot1d(result)

What you will obtain are these two graphs:

.. image:: Parm_tut_est_function.png
.. image:: Parm_tut_residuals.png

Do not hesitate to look at the code for :py:func:`pyqt_fit.plot_fit.plot1d` to examine
how things are plotted. The function should return all the handles you may need
to tune the presentation of the various curves.

Confidence Intervals
--------------------

PyQt-Fit provides bootstrapping methods to compute confidence intervals.

Defining the functions and residuals
------------------------------------

Using the functions/residuals defined for the GUI
-------------------------------------------------

Tuning the residuals
--------------------

